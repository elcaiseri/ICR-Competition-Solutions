{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/elcaiseri/icr-tabularnn-bagging-baseline-cv-0-05?scriptVersionId=139625052\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"This NoteBook takes [ICR | MultiHeads Ensemble Baseline [CV 0.23] & EDA](https://www.kaggle.com/code/elcaiseri/icr-multiheads-ensemble-baseline-cv-0-23-eda) as reference.","metadata":{}},{"cell_type":"markdown","source":"## Imports","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns; sns.set()\nimport matplotlib.pyplot as plt \n\nfrom tqdm.auto import tqdm\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import KFold\n\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\n\nfrom sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:32.823804Z","iopub.execute_input":"2023-07-06T07:19:32.824234Z","iopub.status.idle":"2023-07-06T07:19:35.197455Z","shell.execute_reply.started":"2023-07-06T07:19:32.824194Z","shell.execute_reply":"2023-07-06T07:19:35.196395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Exploration","metadata":{}},{"cell_type":"code","source":"MAIN_DIR = \"/kaggle/input/icr-identify-age-related-conditions/\"\n\ntrain = pd.read_csv(MAIN_DIR + \"train.csv\")\ntest = pd.read_csv(MAIN_DIR + \"test.csv\")\nsub = pd.read_csv(MAIN_DIR + \"sample_submission.csv\")\ngreeks = pd.read_csv(MAIN_DIR + \"greeks.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.199956Z","iopub.execute_input":"2023-07-06T07:19:35.200594Z","iopub.status.idle":"2023-07-06T07:19:35.250581Z","shell.execute_reply.started":"2023-07-06T07:19:35.200558Z","shell.execute_reply":"2023-07-06T07:19:35.249551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.252943Z","iopub.execute_input":"2023-07-06T07:19:35.253277Z","iopub.status.idle":"2023-07-06T07:19:35.290449Z","shell.execute_reply.started":"2023-07-06T07:19:35.253249Z","shell.execute_reply":"2023-07-06T07:19:35.289162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"greeks.head()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.292221Z","iopub.execute_input":"2023-07-06T07:19:35.292777Z","iopub.status.idle":"2023-07-06T07:19:35.306653Z","shell.execute_reply.started":"2023-07-06T07:19:35.292736Z","shell.execute_reply":"2023-07-06T07:19:35.305569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, train.Class.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.310527Z","iopub.execute_input":"2023-07-06T07:19:35.311248Z","iopub.status.idle":"2023-07-06T07:19:35.32275Z","shell.execute_reply.started":"2023-07-06T07:19:35.311214Z","shell.execute_reply":"2023-07-06T07:19:35.321617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"target is unbalanced","metadata":{}},{"cell_type":"code","source":"train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.324487Z","iopub.execute_input":"2023-07-06T07:19:35.324822Z","iopub.status.idle":"2023-07-06T07:19:35.340885Z","shell.execute_reply.started":"2023-07-06T07:19:35.324782Z","shell.execute_reply":"2023-07-06T07:19:35.339779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"there are some missing values in the dataset, let's explore how do we can impute them","metadata":{}},{"cell_type":"markdown","source":"## Data Preproccessing","metadata":{}},{"cell_type":"code","source":"# define heads\nheads = [\n    ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ'],\n    ['BC', 'BD ', 'BN', 'BP', 'BQ', 'BR', 'BZ'], \n    ['CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS', 'CU', 'CW '], \n    ['DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY'], \n    ['EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU'], # EJ is categorical\n    ['FC', 'FD ', 'FE', 'FI', 'FL', 'FR', 'FS'], \n    ['GB', 'GE', 'GF', 'GH', 'GI', 'GL'], \n]\n\nn_heads = len(heads)\n\nn_heads","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.344031Z","iopub.execute_input":"2023-07-06T07:19:35.344641Z","iopub.status.idle":"2023-07-06T07:19:35.354594Z","shell.execute_reply.started":"2023-07-06T07:19:35.344607Z","shell.execute_reply":"2023-07-06T07:19:35.352972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_col = 'EJ'\n\ntrain[cat_col] = train[cat_col].map({\"A\":0, \"B\":1})\ntest[cat_col] = test[cat_col].map({\"A\":0, \"B\":1})","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.356257Z","iopub.execute_input":"2023-07-06T07:19:35.357205Z","iopub.status.idle":"2023-07-06T07:19:35.368609Z","shell.execute_reply.started":"2023-07-06T07:19:35.357173Z","shell.execute_reply":"2023-07-06T07:19:35.367381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_cols = [\"Id\", \"EJ\", \"Class\"]\n\nfeat_cols = [col for col in train.columns if col not in drop_cols]","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.370321Z","iopub.execute_input":"2023-07-06T07:19:35.370894Z","iopub.status.idle":"2023-07-06T07:19:35.381227Z","shell.execute_reply.started":"2023-07-06T07:19:35.370863Z","shell.execute_reply":"2023-07-06T07:19:35.380141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_col =  'Class'\nlabels = train[target_col].values","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.382715Z","iopub.execute_input":"2023-07-06T07:19:35.38328Z","iopub.status.idle":"2023-07-06T07:19:35.392197Z","shell.execute_reply.started":"2023-07-06T07:19:35.383248Z","shell.execute_reply":"2023-07-06T07:19:35.39103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model\n\nThe idea behined MultiHeads is simple, we would use No. of heads as features to predict class/target and ensamble all predictions over multi models (linear, tree and ensemble, etc)\n\n### Metrics","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/datafan07/icr-simple-eda-baseline\ndef balance_logloss(y_true, y_pred):\n    \n    y_pred = np.stack([1-y_pred,y_pred]).T\n    y_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n    y_pred / np.sum(y_pred, axis=1)[:, None]\n    nc = np.bincount(y_true)\n    \n    logloss = (-1/nc[0]*(np.sum(np.where(y_true==0,1,0) * np.log(y_pred[:,0]))) - 1/nc[1]*(np.sum(np.where(y_true!=0,1,0) * np.log(y_pred[:,1])))) / 2\n    \n    return logloss\n\n# balanced preds\ndef boost_preds(yp):\n    c_0, c_1 = yp.sum(axis=0)\n    # Weighted probabilities based on class imbalance\n    prob = yp * np.array([[1/(c_0 if i==0 else c_1) for i in range(yp.shape[1])]])\n    yp_ = prob / np.sum(prob, axis=1, keepdims=1)\n    \n    return yp_\n\n# https://www.kaggle.com/competitions/icr-identify-age-related-conditions/discussion/412507#2291644\ndef more_boost(oof, c):\n    return c*oof / (1 - oof + c*oof)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:19:35.396146Z","iopub.execute_input":"2023-07-06T07:19:35.396545Z","iopub.status.idle":"2023-07-06T07:19:35.408638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Impute","metadata":{}},{"cell_type":"code","source":"all_cols = feat_cols + [cat_col]\nimputer = SimpleImputer(strategy=\"median\")\nimputer.fit(train[all_cols])\n\ntrain[all_cols] = imputer.transform(train[all_cols])\ntest[all_cols] = imputer.transform(test[all_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Normailization","metadata":{}},{"cell_type":"code","source":"# default range (0, 1) but the original range is very large, so i descide to scale it larger range\nsc = StandardScaler() \nsc.fit(train[all_cols])\n\ntrain[all_cols] = sc.transform(train[all_cols])\ntest[all_cols] = sc.transform(test[all_cols])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential, Model\n\n\ndef keras_balance_logloss(y_true, y_pred):\n    y_pred = K.stack([1 - y_pred, y_pred], axis=1)\n    y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n    y_pred /= K.sum(y_pred, axis=1, keepdims=True)\n    nc = K.sum(K.cast(K.equal(y_true, 0), dtype=K.floatx()))\n\n    logloss = (-1 / nc * K.sum(K.cast(K.equal(y_true, 0), dtype=K.floatx()) * K.log(y_pred[:, 0])) -\n               (1 - 1 / nc) * K.sum(K.cast(K.not_equal(y_true, 0), dtype=K.floatx()) * K.log(y_pred[:, 1]))) / 2\n\n    return logloss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(hidden_sizes, lr=0.2, num_categories=2):\n    # Input layer for numeric features\n    input_numerical = layers.Input(shape=(len(feat_cols),))\n\n    x = layers.Dense(hidden_sizes[0], activation='relu')(input_numerical)\n\n    # One-hot encoding for categorical feature\n    input_categorical = layers.Input(shape=(len([cat_col]),))\n    embedded = layers.Embedding(num_categories, hidden_sizes[0])(input_categorical)\n    flattened = layers.Flatten()(embedded)\n\n    # Concatenate numeric and categorical features\n    concatenated = layers.concatenate([x, flattened])\n\n    # Hidden layers\n    for size in hidden_sizes[1:]:\n        concatenated = layers.Dense(size, activation='relu')(concatenated)\n\n    # Output layer\n    output = layers.Dense(1, activation='sigmoid')(concatenated)\n\n    model = Model(inputs=[input_numerical, input_categorical], outputs=output)\n    \n    # Compile the model\n    opt = keras.optimizers.Adam(lr=lr)\n    model.compile(optimizer=opt, loss=keras_balance_logloss)\n\n    return model\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"BAGS = 6\nn_splits = 5 \n\nloss = []\nresult = np.zeros(len(test))\n\ncount = 0\noof = np.zeros(len(train))\n\nfor rs, _ in enumerate(tqdm(range(BAGS), total=BAGS)):\n    train_df, train_cat = train[feat_cols].values, train[cat_col].values.astype(np.int32)\n    test_df, test_cat = test[feat_cols].values, test[cat_col].values.astype(np.int32)\n    \n    gkf = KFold(n_splits=n_splits, shuffle=True, random_state=rs)\n    ids = gkf.split(train_df, labels, groups=greeks.iloc[:, 1:-1].sum(1))\n\n    head_result = []\n    head_loss = []\n    clfs = [create_model([64, 64]), create_model([128, 128]), create_model([128, 64])]\n    for idx, (train_idx, val_idx) in enumerate(ids): \n        # select fold\n        print(\"--> FOLD:\", idx+1, end=\" | \") \n        xr, xrc, xt, xtc = train_df[train_idx], train_cat[train_idx].reshape(-1, 1), train_df[val_idx], train_cat[val_idx].reshape(-1, 1)\n        yr, yt = labels[train_idx], labels[val_idx]\n        \n        # over-sampleing\n        #NUM_POS = np.bincount(yr)[1] # {0: int(NUM_POS*1.3), 1: NUM_POS}\n        #sampler = RandomOverSampler(sampling_strategy=\"auto\", random_state=rs*idx)\n        #xr_, yr = sampler.fit_resample(xr, yr)\n        \n        cw = len(yr) / (2 * np.bincount(yr)) # sklearn docs.\n        cw = dict(zip(np.unique(yr), cw)) \n        \n        # train\n        for clf in clfs:\n            # Train the model\n            clf.fit([xr, xrc], yr, \n                    epochs=100, \n                    batch_size=32, \n                    validation_data=[[xt, xtc], yt], \n                    shuffle=True, \n                    verbose=0, \n                    class_weight=cw,\n                   )\n            \n            yp = clf.predict([xt, xtc], verbose=0)\n            oof[val_idx] += yp[:, 0] / BAGS / len(clfs)\n            count += 1\n            \n            # test\n            result += clf.predict([test_df, test_cat], verbose=0)[:, 0] / BAGS / len(clfs)\n            \n    # tracking loss\n    log_loss = balance_logloss(labels, oof) # \n    loss.append(log_loss)\n    print(\"=> logLoss:\", log_loss)\n            \n    print(\"=\"*12)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:22:49.525042Z","iopub.execute_input":"2023-07-06T07:22:49.525919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now training logs looks better.","metadata":{}},{"cell_type":"markdown","source":"## Evaluate","metadata":{}},{"cell_type":"code","source":"overall_cv = balance_logloss(labels, oof)\n\noverall_cv","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:21:03.520699Z","iopub.execute_input":"2023-07-06T07:21:03.521381Z","iopub.status.idle":"2023-07-06T07:21:03.529993Z","shell.execute_reply.started":"2023-07-06T07:21:03.521329Z","shell.execute_reply":"2023-07-06T07:21:03.528913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.min(loss), np.mean(loss)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:21:03.53155Z","iopub.execute_input":"2023-07-06T07:21:03.532191Z","iopub.status.idle":"2023-07-06T07:21:03.540882Z","shell.execute_reply.started":"2023-07-06T07:21:03.532151Z","shell.execute_reply":"2023-07-06T07:21:03.539624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bst_cv = np.inf\nbst_c = 0\n\nfor b in range(1, 50):\n    oof_ = more_boost(oof, b)\n    cv_loss = balance_logloss(train.Class.values, oof_)\n    if cv_loss < bst_cv:\n        print(b, \"=>\",cv_loss)\n        bst_cv = cv_loss\n        bst_c = b","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:21:03.544779Z","iopub.execute_input":"2023-07-06T07:21:03.545144Z","iopub.status.idle":"2023-07-06T07:21:03.564694Z","shell.execute_reply.started":"2023-07-06T07:21:03.545116Z","shell.execute_reply":"2023-07-06T07:21:03.563717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Watch out! good people, we overfitting.","metadata":{}},{"cell_type":"code","source":"plt.hist(oof, bins=50, label=\"oof\");\nplt.hist(oof_, bins=50, label=\"more oof\");\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:21:03.566243Z","iopub.execute_input":"2023-07-06T07:21:03.566597Z","iopub.status.idle":"2023-07-06T07:21:04.191641Z","shell.execute_reply.started":"2023-07-06T07:21:03.566566Z","shell.execute_reply":"2023-07-06T07:21:04.19042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = result/n_splits #more_boost(result/n_splits, bst_c)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T07:21:04.193431Z","iopub.execute_input":"2023-07-06T07:21:04.193815Z","iopub.status.idle":"2023-07-06T07:21:04.202156Z","shell.execute_reply.started":"2023-07-06T07:21:04.193786Z","shell.execute_reply":"2023-07-06T07:21:04.201007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"sub = test[['Id']].copy()\nsub['Class_0'] = 1-preds\nsub['Class_1'] = preds\nsub.to_csv('submission.csv',index=False)\nsub.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is a baseline, if you have any farther recommandetions, write it in the comment section.\n\n**Upvote** if you like it, your feedback is highly appreciated","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}